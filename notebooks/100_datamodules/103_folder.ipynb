{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use `Folder` for Customs Datasets\n",
    "\n",
    "# Installing Anomalib\n",
    "\n",
    "The easiest way to install anomalib is to use pip. You can install it from the command line using the following command:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple/\n",
      "Requirement already satisfied: anomalib in c:\\users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages (1.0.0.dev0)\n",
      "Requirement already satisfied: albumentations>=1.1.0 in c:\\users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages (from anomalib) (1.3.1)\n",
      "Requirement already satisfied: av>=10.0.0 in c:\\users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages (from anomalib) (11.0.0)\n",
      "Requirement already satisfied: einops>=0.3.2 in c:\\users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages (from anomalib) (0.7.0)\n",
      "Requirement already satisfied: freia>=0.2 in c:\\users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages (from anomalib) (0.2)\n",
      "Requirement already satisfied: imgaug==0.4.0 in c:\\users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages (from anomalib) (0.4.0)\n",
      "Requirement already satisfied: jsonargparse>=4.3 in c:\\users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages (from jsonargparse[signatures]>=4.3->anomalib) (4.27.1)\n",
      "Requirement already satisfied: kornia<0.6.10,>=0.6.6 in c:\\users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages (from anomalib) (0.6.9)\n",
      "Requirement already satisfied: matplotlib>=3.4.3 in c:\\users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages (from anomalib) (3.8.2)\n",
      "Requirement already satisfied: omegaconf>=2.1.1 in c:\\users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages (from anomalib) (2.3.0)\n",
      "Requirement already satisfied: opencv-python>=4.5.3.56 in c:\\users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages (from anomalib) (4.8.1.78)\n",
      "Requirement already satisfied: pandas>=1.1.0 in c:\\users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages (from anomalib) (2.1.3)\n",
      "Requirement already satisfied: pytorch-lightning<1.10.0,>=1.7.0 in c:\\users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages (from anomalib) (1.9.5)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages (from anomalib) (68.0.0)\n",
      "Requirement already satisfied: timm<=0.6.13,>=0.5.4 in c:\\users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages (from anomalib) (0.6.13)\n",
      "Requirement already satisfied: torchmetrics==0.10.3 in c:\\users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages (from anomalib) (0.10.3)\n",
      "Requirement already satisfied: six in c:\\users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages (from imgaug==0.4.0->anomalib) (1.16.0)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages (from imgaug==0.4.0->anomalib) (1.26.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages (from imgaug==0.4.0->anomalib) (1.11.4)\n",
      "Requirement already satisfied: Pillow in c:\\users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages (from imgaug==0.4.0->anomalib) (10.1.0)\n",
      "Requirement already satisfied: scikit-image>=0.14.2 in c:\\users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages (from imgaug==0.4.0->anomalib) (0.22.0)\n",
      "Requirement already satisfied: imageio in c:\\users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages (from imgaug==0.4.0->anomalib) (2.33.0)\n",
      "Requirement already satisfied: Shapely in c:\\users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages (from imgaug==0.4.0->anomalib) (2.0.2)\n",
      "Requirement already satisfied: torch>=1.3.1 in c:\\users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages (from torchmetrics==0.10.3->anomalib) (2.1.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages (from torchmetrics==0.10.3->anomalib) (23.2)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages (from albumentations>=1.1.0->anomalib) (6.0.1)\n",
      "Requirement already satisfied: qudida>=0.0.4 in c:\\users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages (from albumentations>=1.1.0->anomalib) (0.0.4)\n",
      "Requirement already satisfied: opencv-python-headless>=4.1.1 in c:\\users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages (from albumentations>=1.1.0->anomalib) (4.8.1.78)\n",
      "Requirement already satisfied: docstring-parser>=0.15 in c:\\users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages (from jsonargparse[signatures]>=4.3->anomalib) (0.15)\n",
      "Requirement already satisfied: typeshed-client>=2.1.0 in c:\\users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages (from jsonargparse[signatures]>=4.3->anomalib) (2.4.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages (from matplotlib>=3.4.3->anomalib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages (from matplotlib>=3.4.3->anomalib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages (from matplotlib>=3.4.3->anomalib) (4.45.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages (from matplotlib>=3.4.3->anomalib) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages (from matplotlib>=3.4.3->anomalib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages (from matplotlib>=3.4.3->anomalib) (2.8.2)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in c:\\users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages (from omegaconf>=2.1.1->anomalib) (4.9.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages (from pandas>=1.1.0->anomalib) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages (from pandas>=1.1.0->anomalib) (2023.3)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in c:\\users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages (from pytorch-lightning<1.10.0,>=1.7.0->anomalib) (4.66.1)\n",
      "Requirement already satisfied: fsspec>2021.06.0 in c:\\users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages (from fsspec[http]>2021.06.0->pytorch-lightning<1.10.0,>=1.7.0->anomalib) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages (from pytorch-lightning<1.10.0,>=1.7.0->anomalib) (4.8.0)\n",
      "Requirement already satisfied: lightning-utilities>=0.6.0.post0 in c:\\users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages (from pytorch-lightning<1.10.0,>=1.7.0->anomalib) (0.10.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages (from timm<=0.6.13,>=0.5.4->anomalib) (0.16.1)\n",
      "Requirement already satisfied: huggingface-hub in c:\\users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages (from timm<=0.6.13,>=0.5.4->anomalib) (0.19.4)\n",
      "Requirement already satisfied: requests in c:\\users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages (from fsspec[http]>2021.06.0->pytorch-lightning<1.10.0,>=1.7.0->anomalib) (2.31.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages (from fsspec[http]>2021.06.0->pytorch-lightning<1.10.0,>=1.7.0->anomalib) (3.9.1)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in c:\\users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages (from qudida>=0.0.4->albumentations>=1.1.0->anomalib) (1.3.2)\n",
      "Requirement already satisfied: networkx>=2.8 in c:\\users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages (from scikit-image>=0.14.2->imgaug==0.4.0->anomalib) (3.2.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages (from scikit-image>=0.14.2->imgaug==0.4.0->anomalib) (2023.9.26)\n",
      "Requirement already satisfied: lazy_loader>=0.3 in c:\\users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages (from scikit-image>=0.14.2->imgaug==0.4.0->anomalib) (0.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages (from torch>=1.3.1->torchmetrics==0.10.3->anomalib) (3.13.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages (from torch>=1.3.1->torchmetrics==0.10.3->anomalib) (1.12)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages (from torch>=1.3.1->torchmetrics==0.10.3->anomalib) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages (from tqdm>=4.57.0->pytorch-lightning<1.10.0,>=1.7.0->anomalib) (0.4.6)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in c:\\users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages (from typeshed-client>=2.1.0->jsonargparse[signatures]>=4.3->anomalib) (6.1.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<1.10.0,>=1.7.0->anomalib) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<1.10.0,>=1.7.0->anomalib) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<1.10.0,>=1.7.0->anomalib) (1.9.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<1.10.0,>=1.7.0->anomalib) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<1.10.0,>=1.7.0->anomalib) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in c:\\users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<1.10.0,>=1.7.0->anomalib) (4.0.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations>=1.1.0->anomalib) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations>=1.1.0->anomalib) (3.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages (from jinja2->torch>=1.3.1->torchmetrics==0.10.3->anomalib) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning<1.10.0,>=1.7.0->anomalib) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning<1.10.0,>=1.7.0->anomalib) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning<1.10.0,>=1.7.0->anomalib) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning<1.10.0,>=1.7.0->anomalib) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages (from sympy->torch>=1.3.1->torchmetrics==0.10.3->anomalib) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install anomalib"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the Dataset Directory\n",
    "\n",
    "This cell is to ensure we change the directory to have access to the datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# NOTE: Provide the path to the dataset root directory.\n",
    "#   If the datasets is not downloaded, it will be downloaded\n",
    "#   to this directory.\n",
    "dataset_root = Path.cwd().parent.parent / \"datasets\" / \"label2\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Folder Dataset (for Custom Datasets) via API\n",
    "\n",
    "Here we show how one can utilize custom datasets to train anomalib models. A custom dataset in this model can be of the following types:\n",
    "\n",
    "- A dataset with good and bad images.\n",
    "- A dataset with good and bad images as well as mask ground-truths for pixel-wise evaluation.\n",
    "- A dataset with good and bad images that is already split into training and testing sets.\n",
    "\n",
    "To experiment this setting we provide a toy dataset that could be downloaded from the following [https://github.com/openvinotoolkit/anomalib/blob/main/docs/source/data/hazelnut_toy.zip](link). For the rest of the tutorial, we assume that the dataset is downloaded and extracted to `../datasets`, located in the `anomalib` directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pylint: disable=wrong-import-position, wrong-import-order\n",
    "# flake8: noqa\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToPILImage\n",
    "\n",
    "from anomalib.data import TaskType\n",
    "from anomalib.data.folder import Folder, FolderDataset\n",
    "from anomalib.data.utils import InputNormalizationMethod, get_transforms"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataModule\n",
    "\n",
    "Similar to how we created the datamodules for existing benchmarking datasets in the previous tutorials, we can also create an Anomalib datamodule for our custom hazelnut dataset.\n",
    "\n",
    "In addition to the root folder of the dataset, we now also specify which folder contains the normal images, which folder contains the anomalous images, and which folder contains the ground truth masks for the anomalous images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_datamodule = Folder(\n",
    "    root=dataset_root,\n",
    "    normal_dir=\"good\",\n",
    "    abnormal_dir=\"NG\",\n",
    "    task=TaskType.DETECTION,\n",
    "    mask_dir=None,\n",
    "    image_size=256,\n",
    "    normalization=InputNormalizationMethod.NONE,  # don't apply normalization, as we want to visualize the images\n",
    ")\n",
    "folder_datamodule.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['image_path', 'label', 'image', 'mask_path', 'mask', 'boxes']) torch.Size([32, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "# Train images\n",
    "i, data = next(enumerate(folder_datamodule.train_dataloader()))\n",
    "print(data.keys(), data[\"image\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"c:\\Users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"c:\\Users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"c:\\Users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"D:\\hust\\MediaLab\\IAD\\Anomalib\\anomalib\\src\\anomalib\\data\\base\\dataset.py\", line 133, in __getitem__\n    mask = cv2.imread(mask_path, flags=0) / 255.0\nTypeError: unsupported operand type(s) for /: 'NoneType' and 'float'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\hust\\MediaLab\\IAD\\Anomalib\\anomalib\\notebooks\\100_datamodules\\103_folder.ipynb 单元格 10\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/hust/MediaLab/IAD/Anomalib/anomalib/notebooks/100_datamodules/103_folder.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Test images\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/hust/MediaLab/IAD/Anomalib/anomalib/notebooks/100_datamodules/103_folder.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m i, data \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39menumerate\u001b[39;49m(folder_datamodule\u001b[39m.\u001b[39;49mtest_dataloader()))\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/hust/MediaLab/IAD/Anomalib/anomalib/notebooks/100_datamodules/103_folder.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(data\u001b[39m.\u001b[39mkeys(), data[\u001b[39m\"\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[1;32mc:\\Users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    631\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1345\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1343\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1344\u001b[0m     \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_task_info[idx]\n\u001b[1;32m-> 1345\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_data(data)\n",
      "File \u001b[1;32mc:\\Users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1371\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1369\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_put_index()\n\u001b[0;32m   1370\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[1;32m-> 1371\u001b[0m     data\u001b[39m.\u001b[39;49mreraise()\n\u001b[0;32m   1372\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages\\torch\\_utils.py:694\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m    691\u001b[0m     \u001b[39m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[0;32m    692\u001b[0m     \u001b[39m# instantiate since we don't know how to\u001b[39;00m\n\u001b[0;32m    693\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(msg) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 694\u001b[0m \u001b[39mraise\u001b[39;00m exception\n",
      "\u001b[1;31mTypeError\u001b[0m: Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"c:\\Users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"c:\\Users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"c:\\Users\\bonozhou\\.conda\\envs\\anomalib_env\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"D:\\hust\\MediaLab\\IAD\\Anomalib\\anomalib\\src\\anomalib\\data\\base\\dataset.py\", line 133, in __getitem__\n    mask = cv2.imread(mask_path, flags=0) / 255.0\nTypeError: unsupported operand type(s) for /: 'NoneType' and 'float'\n"
     ]
    }
   ],
   "source": [
    "# Test images\n",
    "i, data = next(enumerate(folder_datamodule.test_dataloader()))\n",
    "print(data.keys(), data[\"image\"].shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen above, creating the dataloaders are pretty straghtforward, which could be directly used for training/testing/inference. We could visualize samples from the dataloaders as well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = ToPILImage()(data[\"image\"][0].clone())\n",
    "msk = ToPILImage()(data[\"mask\"][0]).convert(\"RGB\")\n",
    "\n",
    "Image.fromarray(np.hstack((np.array(img), np.array(msk))))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Folder` data module offers much more flexibility cater all different sorts of needs. Please refer to the documentation for more details.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Torch Dataset\n",
    "\n",
    "As in earlier examples, we can also create a standalone PyTorch dataset instance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FolderDataset??"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create `FolderDataset` we need to create the albumentations object that applies transforms to the input image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_transforms??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (256, 256)\n",
    "transform = get_transforms(image_size=256, normalization=InputNormalizationMethod.NONE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Task\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_dataset_classification_train = FolderDataset(\n",
    "    normal_dir=dataset_root / \"good\",\n",
    "    abnormal_dir=dataset_root / \"crack\",\n",
    "    split=\"train\",\n",
    "    transform=transform,\n",
    "    task=TaskType.CLASSIFICATION,\n",
    ")\n",
    "folder_dataset_classification_train.setup()\n",
    "folder_dataset_classification_train.samples.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the first sample in the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = folder_dataset_classification_train[0]\n",
    "print(data.keys(), data[\"image\"].shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen above, when we choose `classification` task and `train` split, the dataset only returns `image`. This is mainly because training only requires normal images and no labels. Now let's try `test` split for the `classification` task\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder Classification Test Set\n",
    "folder_dataset_classification_test = FolderDataset(\n",
    "    normal_dir=dataset_root / \"good\",\n",
    "    abnormal_dir=dataset_root / \"crack\",\n",
    "    split=\"test\",\n",
    "    transform=transform,\n",
    "    task=TaskType.CLASSIFICATION,\n",
    ")\n",
    "folder_dataset_classification_test.setup()\n",
    "folder_dataset_classification_test.samples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = folder_dataset_classification_test[0]\n",
    "print(data.keys(), data[\"image\"].shape, data[\"image_path\"], data[\"label\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Segmentation Task\n",
    "\n",
    "It is also possible to configure the Folder dataset for the segmentation task, where the dataset object returns image and ground-truth mask.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder Segmentation Train Set\n",
    "folder_dataset_segmentation_train = FolderDataset(\n",
    "    normal_dir=dataset_root / \"good\",\n",
    "    abnormal_dir=dataset_root / \"crack\",\n",
    "    split=\"train\",\n",
    "    transform=transform,\n",
    "    mask_dir=dataset_root / \"mask\" / \"crack\",\n",
    "    task=TaskType.SEGMENTATION,\n",
    ")\n",
    "folder_dataset_segmentation_train.setup()  # like the datamodule, the dataset needs to be set up before use\n",
    "folder_dataset_segmentation_train.samples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder Segmentation Test Set\n",
    "folder_dataset_segmentation_test = FolderDataset(\n",
    "    normal_dir=dataset_root / \"good\",\n",
    "    abnormal_dir=dataset_root / \"crack\",\n",
    "    split=\"test\",\n",
    "    transform=transform,\n",
    "    mask_dir=dataset_root / \"mask\" / \"crack\",\n",
    "    task=TaskType.SEGMENTATION,\n",
    ")\n",
    "folder_dataset_segmentation_test.setup()  # like the datamodule, the dataset needs to be set up before use\n",
    "folder_dataset_segmentation_test.samples.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = folder_dataset_segmentation_test[3]\n",
    "print(data.keys(), data[\"image\"].shape, data[\"mask\"].shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the image and the mask...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = ToPILImage()(data[\"image\"].clone())\n",
    "msk = ToPILImage()(data[\"mask\"]).convert(\"RGB\")\n",
    "\n",
    "Image.fromarray(np.hstack((np.array(img), np.array(msk))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transform' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\hust\\MediaLab\\IAD\\Anomalib\\anomalib\\notebooks\\100_datamodules\\103_folder.ipynb 单元格 32\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/hust/MediaLab/IAD/Anomalib/anomalib/notebooks/100_datamodules/103_folder.ipynb#X43sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m folder_dataset_classification_train \u001b[39m=\u001b[39m FolderDataset(\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/hust/MediaLab/IAD/Anomalib/anomalib/notebooks/100_datamodules/103_folder.ipynb#X43sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     normal_dir\u001b[39m=\u001b[39mdataset_root \u001b[39m/\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mgood\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/hust/MediaLab/IAD/Anomalib/anomalib/notebooks/100_datamodules/103_folder.ipynb#X43sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     abnormal_dir\u001b[39m=\u001b[39mdataset_root \u001b[39m/\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mNG\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/hust/MediaLab/IAD/Anomalib/anomalib/notebooks/100_datamodules/103_folder.ipynb#X43sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     split\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/hust/MediaLab/IAD/Anomalib/anomalib/notebooks/100_datamodules/103_folder.ipynb#X43sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     transform\u001b[39m=\u001b[39mtransform,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/hust/MediaLab/IAD/Anomalib/anomalib/notebooks/100_datamodules/103_folder.ipynb#X43sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     task\u001b[39m=\u001b[39mTaskType\u001b[39m.\u001b[39mDETECTION,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/hust/MediaLab/IAD/Anomalib/anomalib/notebooks/100_datamodules/103_folder.ipynb#X43sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m )\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/hust/MediaLab/IAD/Anomalib/anomalib/notebooks/100_datamodules/103_folder.ipynb#X43sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m folder_dataset_classification_train\u001b[39m.\u001b[39msetup()\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/hust/MediaLab/IAD/Anomalib/anomalib/notebooks/100_datamodules/103_folder.ipynb#X43sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m folder_dataset_classification_train\u001b[39m.\u001b[39msamples\u001b[39m.\u001b[39mhead()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'transform' is not defined"
     ]
    }
   ],
   "source": [
    "folder_dataset_classification_train = FolderDataset(\n",
    "    normal_dir=dataset_root / \"good\",\n",
    "    abnormal_dir=dataset_root / \"NG\",\n",
    "    split=\"train\",\n",
    "    task=TaskType.DETECTION,\n",
    ")\n",
    "folder_dataset_classification_train.setup()\n",
    "folder_dataset_classification_train.samples.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anomalib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ae223df28f60859a2f400fae8b3a1034248e0a469f5599fd9a89c32908ed7a84"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
